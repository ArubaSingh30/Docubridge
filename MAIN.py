"""
main.py – Flask web app that turns Excel financial models into an interactive,
AI-powered assistant. Users upload a spreadsheet, ask questions in plain
English, and receive answers generated by Cohere’s Command-R model.
"""
from dotenv import load_dotenv
load_dotenv()  # reads .env and sets os.environ

import os
import uuid
import json
import logging
import re
from zipfile import BadZipFile

import pandas as pd
import markdown2
import cohere
from flask import (
    Flask, flash, redirect, render_template,
    request, session, url_for
)
from openpyxl import load_workbook
from werkzeug.exceptions import RequestEntityTooLarge

# ─────────────────────────────── Flask setup ─────────────────────────────── #

app = Flask(__name__)
app.secret_key = os.getenv("FLASK_API_KEY", "dev-secret")

# Accept only Excel files up to 5 MB
app.config["MAX_CONTENT_LENGTH"] = 5 * 1024 * 1024
ALLOWED_EXTENSIONS = {".xls", ".xlsx"}

# Rotating cache (keyed by UUID stored in the session)
UPLOAD_CACHE: dict[str, dict] = {}

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ──────────────────────────────── Helpers ────────────────────────────────── #

ERROR_TOKENS = {"#DIV/0!", "#N/A", "#VALUE!", "#REF!", "#NAME?", "#NUM!"}


def allowed_file(filename: str) -> bool:
    """Return True if filename has a valid Excel extension."""
    return os.path.splitext(filename)[1].lower() in ALLOWED_EXTENSIONS


def process_dataframe(df: pd.DataFrame) -> dict:
    """
    Lightweight profiling – returns HTML preview, stats, trends, ratios,
    data-quality notes, and a JSON snippet used to prime the LLM.
    """
    error_cells, missing_cells = [], []

    # Locate Excel error tokens and NaNs
    for r, row in df.iterrows():
        for col, val in row.items():
            cell = f"{col}{r + 2}"  # +2 → account for header row
            if isinstance(val, str) and val in ERROR_TOKENS:
                error_cells.append(cell)
            elif pd.isna(val):
                missing_cells.append(cell)

    table_html = (
        df.replace(list(ERROR_TOKENS), "ERROR")
        .head(10)
        .to_html(classes="table table-striped", index=False, border=0)
    )

    # Numeric summaries
    numeric_cols = df.select_dtypes("number").columns
    if numeric_cols.empty:
        stats_text = "No numeric columns found."
    else:
        stats_text = "; ".join(
            f"{c}: sum={df[c].sum(skipna=True):,.2f}, "
            f"mean={df[c].mean(skipna=True):,.2f}"
            for c in numeric_cols
        )

    # Profit-margin ratio (if columns exist)
    revenue_col = next((c for c in df.columns if "revenue" in c.lower()), None)
    profit_col = next((c for c in df.columns if re.search(r"profit|income", c, re.I)), None)
    if revenue_col and profit_col and df[revenue_col].sum() > 0:
        margin = (df[profit_col].sum() / df[revenue_col].sum()) * 100
        ratio_text = f"Overall Profit Margin: {margin:.2f}%"
    else:
        ratio_text = "No key financial ratios calculated."

    # Simple trend detection (MoM change of numeric cols)
    datetime_cols = df.select_dtypes("datetime64[ns]").columns
    trends = []
    if datetime_cols.any():
        dc = datetime_cols[0]
        ts = (
            df[[dc] + list(numeric_cols)]
            .dropna(subset=[dc])
            .sort_values(dc)
            .set_index(dc)
            .resample("M")
            .sum()
        )
        for c in numeric_cols:
            pct = ts[c].pct_change().mean() * 100
            if pd.notnull(pct):
                direction = "grew" if pct > 0 else "declined"
                trends.append(f"{c} {direction} by an average of {pct:.1f}% MoM")
    trend_text = "; ".join(trends) or "No clear time-series trends detected."

    # Data-quality notes
    notes = []
    if error_cells:
        notes.append(f"Errors in cells e.g. {error_cells[0]}")
    if missing_cells:
        notes.append(f"Missing values in cells e.g. {missing_cells[0]}")
    prefix = "Note: " + " ".join(notes) if notes else ""

    head_text = json.dumps(df.head(3).to_dict(orient="records"), indent=2, default=str)

    return {
        "table_html": table_html,
        "stats_text": stats_text,
        "trend_text": trend_text,
        "ratio_text": ratio_text,
        "prefix": prefix,
        "head_text": head_text,
    }


def build_prompt(meta: dict, num_rows: int, cols: list[str], question: str) -> str:
    """Assemble the final prompt for Cohere’s Command-R model."""
    return (
        f'{meta["prefix"]} '
        "Analyze the following spreadsheet data. "
        f"The sheet has {num_rows} rows and columns: {cols}. "
        f"Key Stats: {meta['stats_text']}. "
        f"Financial Ratios: {meta['ratio_text']}. "
        f"Time-series Trends: {meta['trend_text']}. "
        f"Data Preview (first 3 rows): {meta['head_text']}. "
        f'Given this context, answer the user\'s question: "{question}".'
    )

# ─────────────────────────── Error handlers ──────────────────────────────── #


@app.errorhandler(413)
@app.errorhandler(RequestEntityTooLarge)
def handle_file_too_large(_: Exception):
    """Gracefully handle files larger than 5 MB."""
    logging.warning("Upload failed – file too large.")
    flash("File is too large (maximum 5 MB).")
    return redirect(url_for("index"))

# ─────────────────────────────── Routes ──────────────────────────────────── #


@app.route("/")
def index():
    """Landing page – form for upload + question."""
    return render_template("index.html")


@app.route("/upload", methods=["POST"])
def upload():
    """
    First upload + initial question:

    1. Validate & load Excel into DataFrame (first sheet).
    2. Profile data and craft LLM prompt.
    3. Query Cohere and render response.
    4. Stash DataFrame/workbook in session for follow-up questions.
    """
    file = request.files.get("excelFile")
    question = request.form.get("userQuestion", "").strip()

    if not file or not file.filename:
        flash("No file selected.")
        return redirect(url_for("index"))
    if not allowed_file(file.filename):
        flash("Unsupported file type. Please upload .xls or .xlsx.")
        return redirect(url_for("index"))

    logging.info("File uploaded: %s | Question: %s", file.filename, question)

    try:
        # read every sheet into a dict: sheet name → DataFrame
        sheets: dict[str, pd.DataFrame] = pd.read_excel(file, sheet_name=None, dtype=object)
        # pick the first sheet as the default
        default_sheet = list(sheets.keys())[0]
        df = sheets[default_sheet]
    except (ValueError, BadZipFile) as exc:
        logging.error("Unreadable Excel file – %s", exc)
        flash("I couldn’t read that file. Please check the format.")
        return redirect(url_for("index"))

    # Load workbook too (for later formula explanations)
    wb = None
    if file.filename.endswith(".xlsx"):
        try:
            file.stream.seek(0)
            wb = load_workbook(file.stream, data_only=False)
        except Exception:
            wb = None  # Non-critical – continue without workbook

    meta = process_dataframe(df)
    prompt = build_prompt(meta, len(df), df.columns.tolist(), question)
    logging.debug("Prompt length: %d chars", len(prompt))

    try:
        co = cohere.Client(os.getenv("COHERE_API_KEY"))
        ai_answer = co.chat(model="command-r", message=prompt).text.strip()
    except Exception as exc:
        logging.error("Cohere API failed – %s", exc)
        flash("The AI service is currently unavailable. Try again later.")
        return redirect(url_for("index"))

    # Cache dataframe for follow-ups
    upload_id = str(uuid.uuid4())
    UPLOAD_CACHE[upload_id] = {
        "sheets": sheets,
        "active_sheet": default_sheet,
        "wb": wb,
    }
    session["upload_id"] = upload_id

    return render_template(
        "assistant.html",
        sheet_names=list(sheets.keys()),
        active_sheet=default_sheet,
        result={"question": question, "answer": markdown2.markdown(ai_answer)},
        table_html=meta["table_html"],
        filename=file.filename,
    )


@app.route("/ask", methods=["POST"])
def ask():
    """
    Follow-up questions reuse the cached DataFrame.

    Special cases:
    • If the user asks for a formula (“excel formula …”) → generate one.
    • If they mention a cell & “formula” (e.g. “Explain formula in cell D15”)
      and we have the workbook → explain that specific formula.
    """
    cache = UPLOAD_CACHE.get(session.get("upload_id", ""))
    if not cache:
        flash("Session expired – please upload a new file.")
        return redirect(url_for("index"))

    df = cache["sheets"][cache["active_sheet"]]
    wb = cache["wb"]
    cols = df.columns.tolist()
    question = request.form.get("userQuestion", "").strip()
    logging.info("Follow-up question: %s", question)

    meta = process_dataframe(df)

    # Branch: formula generation / explanation
    if re.search(r"(how do i calculate|what is the formula|excel formula)", question, re.I):
        prompt = (
            "Provide an Excel formula and a brief explanation for the request:\n"
            f"{question}"
        )
    else:
        cell_match = re.search(r"cell\s*([A-Za-z]+\d+)", question, re.I)
        if wb and "formula" in question.lower() and cell_match:
            ref = cell_match.group(1).upper()
            try:
                raw_formula = wb.active[ref].value or ""
                prompt = (
                    f"Explain this Excel formula in simple terms: {raw_formula}"
                    if raw_formula else f"Cell {ref} is empty."
                )
            except Exception:
                prompt = f"Could not access cell {ref}."
        else:
            prompt = build_prompt(meta, len(df), cols, question)

    try:
        co = cohere.Client(os.getenv("COHERE_API_KEY"))
        ai_answer = co.chat(model="command-r", message=prompt).text.strip()
    except Exception as exc:
        logging.error("Cohere follow-up failed – %s", exc)
        return "The AI service is currently unavailable.", 503

    return render_template(
        "assistant.html",
        result={"question": question, "answer": markdown2.markdown(ai_answer)},
        table_html=meta["table_html"],
        filename=None,
    )

@app.route("/switch-sheet", methods=["POST"])
def switch_sheet():
    upload_id = session.get("upload_id", "")
    cache = UPLOAD_CACHE.get(upload_id)
    if not cache:
        flash("Session expired — please upload again.")
        return redirect(url_for("index"))

    chosen = request.form["sheetName"]
    cache["active_sheet"] = chosen

    # re-profile the newly‐selected sheet
    df = cache["sheets"][chosen]
    meta = process_dataframe(df)

    return render_template(
        "assistant.html",
        sheet_names=list(cache["sheets"].keys()),
        active_sheet=chosen,
        result=None,                     # no AI answer yet
        table_html=meta["table_html"],
        filename=None,
    )

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
